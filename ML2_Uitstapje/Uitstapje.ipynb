{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pokedex_number</th>\n",
       "      <th>name</th>\n",
       "      <th>generation</th>\n",
       "      <th>status</th>\n",
       "      <th>species</th>\n",
       "      <th>type_number</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>height_m</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>...</th>\n",
       "      <th>against_ground</th>\n",
       "      <th>against_flying</th>\n",
       "      <th>against_psychic</th>\n",
       "      <th>against_bug</th>\n",
       "      <th>against_rock</th>\n",
       "      <th>against_ghost</th>\n",
       "      <th>against_dragon</th>\n",
       "      <th>against_dark</th>\n",
       "      <th>against_steel</th>\n",
       "      <th>against_fairy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Seed Pokémon</td>\n",
       "      <td>2</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Seed Pokémon</td>\n",
       "      <td>2</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Seed Pokémon</td>\n",
       "      <td>2</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Lizard Pokémon</td>\n",
       "      <td>1</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flame Pokémon</td>\n",
       "      <td>1</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pokedex_number        name  generation  status         species  \\\n",
       "0               1   Bulbasaur           1  Normal    Seed Pokémon   \n",
       "1               2     Ivysaur           1  Normal    Seed Pokémon   \n",
       "2               3    Venusaur           1  Normal    Seed Pokémon   \n",
       "4               4  Charmander           1  Normal  Lizard Pokémon   \n",
       "5               5  Charmeleon           1  Normal   Flame Pokémon   \n",
       "\n",
       "   type_number type_1  type_2  height_m  weight_kg  ...  against_ground  \\\n",
       "0            2  Grass  Poison       0.7        6.9  ...             1.0   \n",
       "1            2  Grass  Poison       1.0       13.0  ...             1.0   \n",
       "2            2  Grass  Poison       2.0      100.0  ...             1.0   \n",
       "4            1   Fire     NaN       0.6        8.5  ...             2.0   \n",
       "5            1   Fire     NaN       1.1       19.0  ...             2.0   \n",
       "\n",
       "  against_flying against_psychic against_bug  against_rock  against_ghost  \\\n",
       "0            2.0             2.0         1.0           1.0            1.0   \n",
       "1            2.0             2.0         1.0           1.0            1.0   \n",
       "2            2.0             2.0         1.0           1.0            1.0   \n",
       "4            1.0             1.0         0.5           2.0            1.0   \n",
       "5            1.0             1.0         0.5           2.0            1.0   \n",
       "\n",
       "   against_dragon  against_dark  against_steel  against_fairy  \n",
       "0             1.0           1.0            1.0            0.5  \n",
       "1             1.0           1.0            1.0            0.5  \n",
       "2             1.0           1.0            1.0            0.5  \n",
       "4             1.0           1.0            0.5            0.5  \n",
       "5             1.0           1.0            0.5            0.5  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\wesse\\Avans\\Minor\\pokedex_(Update_04.21).csv')\n",
    "df = df.drop(['Unnamed: 0', 'german_name', 'japanese_name'], axis=1)\n",
    "# for all rows with a duplicate pokedex_number, keep the first row\n",
    "df = df.drop_duplicates(subset='pokedex_number', keep='first')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation        int64\n",
      "total_points      int64\n",
      "hp                int64\n",
      "attack            int64\n",
      "defense           int64\n",
      "sp_attack         int64\n",
      "sp_defense        int64\n",
      "speed             int64\n",
      "catch_rate      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# define the features and target\n",
    "features = ['generation', 'total_points', 'hp', 'attack', 'defense', 'sp_attack', 'sp_defense', 'speed', 'catch_rate']\n",
    "target = 'status'\n",
    "# train test split\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "X_train = train[features]\n",
    "X_test = test[features]\n",
    "y_train = train[target]\n",
    "y_test = test[target]\n",
    "print(df[features].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[  3   0   1   0]\n",
      " [  0   0   2   4]\n",
      " [  0   0 244   2]\n",
      " [  1   0   3  10]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Legendary       0.75      0.75      0.75         4\n",
      "     Mythical       0.00      0.00      0.00         6\n",
      "       Normal       0.98      0.99      0.98       246\n",
      "Sub Legendary       0.62      0.71      0.67        14\n",
      "\n",
      "     accuracy                           0.95       270\n",
      "    macro avg       0.59      0.61      0.60       270\n",
      " weighted avg       0.93      0.95      0.94       270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# create a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# fit the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# predict using the model\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate the elapsed time in milliseconds\n",
    "elapsed_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "print('Logistic Regression')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# get macro avg results\n",
    "macro_avg = classification_report(y_test, y_pred, output_dict=True)['macro avg']\n",
    "precision, recall, f1 = macro_avg['precision'], macro_avg['recall'], macro_avg['f1-score']\n",
    "\n",
    "# write results on a new line in the results.csv file\n",
    "with open(r'C:\\Users\\wesse\\Avans\\Minor\\ML2_Uitstapje\\results.csv', 'a') as f:\n",
    "    f.write(f'\\nLogistic Regression, {precision}, {recall}, {f1}, {elapsed_time_ms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[[  3   0   1   0]\n",
      " [  0   4   1   1]\n",
      " [  0   1 244   1]\n",
      " [  2   0   0  12]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Legendary       0.60      0.75      0.67         4\n",
      "     Mythical       0.80      0.67      0.73         6\n",
      "       Normal       0.99      0.99      0.99       246\n",
      "Sub Legendary       0.86      0.86      0.86        14\n",
      "\n",
      "     accuracy                           0.97       270\n",
      "    macro avg       0.81      0.82      0.81       270\n",
      " weighted avg       0.97      0.97      0.97       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a random_forest model\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# fit the model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# predict using the model\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate the elapsed time in milliseconds\n",
    "elapsed_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "print('Random Forest')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# get macro avg results\n",
    "macro_avg = classification_report(y_test, y_pred, output_dict=True)['macro avg']\n",
    "precision, recall, f1 = macro_avg['precision'], macro_avg['recall'], macro_avg['f1-score']\n",
    "\n",
    "# write results on a new line in the results.csv file\n",
    "with open(r'C:\\Users\\wesse\\Avans\\Minor\\ML2_Uitstapje\\results.csv', 'a') as f:\n",
    "    f.write(f'\\nRandom Forest, {precision}, {recall}, {f1}, {elapsed_time_ms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pokedex_number</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>376</td>\n",
       "      <td>Metagross</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Sub Legendary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>808</td>\n",
       "      <td>Meltan</td>\n",
       "      <td>Mythical</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>248</td>\n",
       "      <td>Tyranitar</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Mythical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>790</td>\n",
       "      <td>Cosmoem</td>\n",
       "      <td>Legendary</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Mythical</td>\n",
       "      <td>Sub Legendary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>488</td>\n",
       "      <td>Cresselia</td>\n",
       "      <td>Sub Legendary</td>\n",
       "      <td>Legendary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>486</td>\n",
       "      <td>Regigigas</td>\n",
       "      <td>Sub Legendary</td>\n",
       "      <td>Legendary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pokedex_number       name         status         y_pred\n",
       "450             376  Metagross         Normal  Sub Legendary\n",
       "944             808     Meltan       Mythical         Normal\n",
       "300             248  Tyranitar         Normal       Mythical\n",
       "923             790    Cosmoem      Legendary         Normal\n",
       "842             719    Diancie       Mythical  Sub Legendary\n",
       "584             488  Cresselia  Sub Legendary      Legendary\n",
       "581             486  Regigigas  Sub Legendary      Legendary"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the wrong guesses from the random forest model to a new dataframe\n",
    "test['y_pred'] = y_pred\n",
    "false_predictions = test[test['status'] != test['y_pred']]\n",
    "false_predictions[['pokedex_number', 'name', 'status', 'y_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 1ms/step - loss: 1.2559 - accuracy: 0.5096\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9565 - accuracy: 0.7261\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.8615\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.8885\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.8917\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.8917\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8917\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8917\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8917\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8917\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8917\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8917\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8917\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8917\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8917\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8917\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8917\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8917\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8917\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8917\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8917\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8917\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8917\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8917\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8917\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8933\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8933\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8933\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8965\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8997\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.9029\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9076\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9108\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.9108\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9108\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9140\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9124\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9140\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9140\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9220\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9252\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9236\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9236\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9220\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9220\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9236\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9252\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9252\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9283\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9283\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9268\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9299\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9315\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9299\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9315\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9331\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9347\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9363\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9347\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9395\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9347\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9395\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9379\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9411\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9427\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9395\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9411\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9459\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9411\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9427\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9443\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9411\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9443\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9443\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9427\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9427\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9427\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9427\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9411\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9443\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9427\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9411\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9411\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9411\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9411\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9427\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9427\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9459\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9411\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9395\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9427\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9475\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9411\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9411\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9475\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9443\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9427\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9459\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9475\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9443\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Keras Sequential Model\n",
      "Accuracy: 0.9481481313705444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60         4\n",
      "           1       1.00      0.17      0.29         6\n",
      "           2       0.97      1.00      0.98       246\n",
      "           3       0.70      0.50      0.58        14\n",
      "\n",
      "    accuracy                           0.95       270\n",
      "   macro avg       0.79      0.60      0.61       270\n",
      "weighted avg       0.95      0.95      0.94       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convert string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# create a Keras Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))  # 4 output neurons for 4 classes\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "# predict using the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate the elapsed time in milliseconds\n",
    "elapsed_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Keras Sequential Model\\nAccuracy: {accuracy}')\n",
    "\n",
    "# get classification report\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# get macro avg results\n",
    "macro_avg = classification_report(y_test, y_pred_classes, output_dict=True)['macro avg']\n",
    "precision, recall, f1 = macro_avg['precision'], macro_avg['recall'], macro_avg['f1-score']\n",
    "\n",
    "# write results on a new line in the results.csv file\n",
    "with open(r'C:\\Users\\wesse\\Avans\\Minor\\ML2_Uitstapje\\results.csv', 'a') as f:\n",
    "    f.write(f'\\nNeural Network(1L 8N), {precision}, {recall}, {f1}, {elapsed_time_ms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 1ms/step - loss: 0.7933 - accuracy: 0.8025\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8917\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8917\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8949\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.9092\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9108\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9172\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9252\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9331\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9299\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9236\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9363\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9299\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9459\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9411\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9490\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9443\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9506\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9506\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9602\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9538\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9506\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9666\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9618\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9570\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9570\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9602\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9650\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9666\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9618\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9650\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9745\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9682\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9697\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9729\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9729\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9729\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9729\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9761\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9777\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9729\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9761\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9809\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9809\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9809\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9841\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9761\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9841\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9793\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9793\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9841\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9809\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9809\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9857\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9841\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9873\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9809\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9841\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9825\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9857\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9873\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9904\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9920\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9904\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9841\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9920\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9904\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9904\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9904\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9920\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9904\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9936\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9952\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9968\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9952\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9968\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9936\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9952\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9952\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9952\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9952\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9952\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9952\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9968\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9952\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9952\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9952\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9968\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9920\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9936\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9968\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9968\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9968\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Keras Sequential Model with 2 Hidden Layers\n",
      "Accuracy: 0.9407407641410828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60         4\n",
      "           1       0.40      0.33      0.36         6\n",
      "           2       0.98      0.99      0.98       246\n",
      "           3       0.56      0.36      0.43        14\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.61      0.61      0.60       270\n",
      "weighted avg       0.93      0.94      0.94       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# create a Keras Sequential model with 2 hidden layers\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # first hidden layer with 64 neurons\n",
    "model.add(Dense(32, activation='relu'))  # second hidden layer with 32 neurons\n",
    "model.add(Dense(4, activation='softmax'))  # output layer with 4 neurons for 4 classes\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "# predict using the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate the elapsed time in milliseconds\n",
    "elapsed_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Keras Sequential Model with 2 Hidden Layers\\nAccuracy: {accuracy}')\n",
    "\n",
    "# get classification report\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# get macro avg results\n",
    "macro_avg = classification_report(y_test, y_pred_classes, output_dict=True)['macro avg']\n",
    "precision, recall, f1 = macro_avg['precision'], macro_avg['recall'], macro_avg['f1-score']\n",
    "\n",
    "# write results on a new line in the results.csv file\n",
    "with open(r'C:\\Users\\wesse\\Avans\\Minor\\ML2_Uitstapje\\results.csv', 'a') as f:\n",
    "    f.write(f'\\nNeural Network(2L 64N-32N), {precision}, {recall}, {f1}, {elapsed_time_ms}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesse\\anaconda3\\envs\\tensorenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-09-28 15:39:56,799] A new study created in memory with name: no-name-a6c5a897-7517-4532-a6f0-97a7d7307eba\n",
      "C:\\Users\\wesse\\AppData\\Local\\Temp\\ipykernel_29296\\320709178.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  model.compile(optimizer=Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)),\n",
      "[I 2024-09-28 15:40:05,276] Trial 0 finished with value: 0.9074074029922485 and parameters: {'units_layer_1': 127, 'n_layers': 1, 'units_layer_2': 57, 'learning_rate': 0.015289953489961811}. Best is trial 0 with value: 0.9074074029922485.\n",
      "[I 2024-09-28 15:40:12,906] Trial 1 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 5, 'n_layers': 1, 'units_layer_2': 44, 'learning_rate': 0.0009242987200728996}. Best is trial 1 with value: 0.9111111164093018.\n",
      "[I 2024-09-28 15:40:21,739] Trial 2 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 64, 'n_layers': 1, 'units_layer_2': 27, 'learning_rate': 0.003443328704349796}. Best is trial 2 with value: 0.9444444179534912.\n",
      "[I 2024-09-28 15:40:30,961] Trial 3 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 74, 'n_layers': 2, 'units_layer_2': 113, 'units_layer_3': 58, 'learning_rate': 4.740480084629945e-05}. Best is trial 2 with value: 0.9444444179534912.\n",
      "[I 2024-09-28 15:40:40,073] Trial 4 finished with value: 0.9222221970558167 and parameters: {'units_layer_1': 44, 'n_layers': 1, 'units_layer_2': 70, 'learning_rate': 7.587087778574721e-05}. Best is trial 2 with value: 0.9444444179534912.\n",
      "[I 2024-09-28 15:40:49,100] Trial 5 finished with value: 0.9074074029922485 and parameters: {'units_layer_1': 25, 'n_layers': 2, 'units_layer_2': 7, 'units_layer_3': 32, 'learning_rate': 1.899909046862139e-05}. Best is trial 2 with value: 0.9444444179534912.\n",
      "[I 2024-09-28 15:40:58,638] Trial 6 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 25, 'n_layers': 2, 'units_layer_2': 24, 'units_layer_3': 25, 'learning_rate': 8.411714716773071e-05}. Best is trial 2 with value: 0.9444444179534912.\n",
      "[I 2024-09-28 15:41:07,571] Trial 7 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 4, 'n_layers': 1, 'units_layer_2': 120, 'learning_rate': 0.0010291986006254522}. Best is trial 2 with value: 0.9444444179534912.\n",
      "[I 2024-09-28 15:41:16,992] Trial 8 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 122, 'n_layers': 2, 'units_layer_2': 74, 'units_layer_3': 21, 'learning_rate': 0.0003152307543302754}. Best is trial 8 with value: 0.9481481313705444.\n",
      "[I 2024-09-28 15:41:25,548] Trial 9 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 5, 'n_layers': 1, 'units_layer_2': 33, 'learning_rate': 9.940649403046379e-05}. Best is trial 8 with value: 0.9481481313705444.\n",
      "[I 2024-09-28 15:41:36,342] Trial 10 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 125, 'n_layers': 3, 'units_layer_2': 82, 'units_layer_3': 122, 'units_layer_4': 35, 'learning_rate': 0.09709718293725979}. Best is trial 8 with value: 0.9481481313705444.\n",
      "[I 2024-09-28 15:41:47,453] Trial 11 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 88, 'n_layers': 3, 'units_layer_2': 93, 'units_layer_3': 8, 'units_layer_4': 124, 'learning_rate': 0.0011969777776089897}. Best is trial 8 with value: 0.9481481313705444.\n",
      "[I 2024-09-28 15:41:57,527] Trial 12 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 101, 'n_layers': 2, 'units_layer_2': 56, 'units_layer_3': 95, 'learning_rate': 0.0054434336696066515}. Best is trial 8 with value: 0.9481481313705444.\n",
      "[I 2024-09-28 15:42:08,399] Trial 13 finished with value: 0.9592592716217041 and parameters: {'units_layer_1': 104, 'n_layers': 2, 'units_layer_2': 60, 'units_layer_3': 103, 'learning_rate': 0.008596473705813212}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:42:19,215] Trial 14 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 105, 'n_layers': 3, 'units_layer_2': 95, 'units_layer_3': 79, 'units_layer_4': 103, 'learning_rate': 0.0002907306216713699}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:42:29,354] Trial 15 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 111, 'n_layers': 2, 'units_layer_2': 74, 'units_layer_3': 122, 'learning_rate': 0.04458859420687298}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:42:39,390] Trial 16 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 86, 'n_layers': 2, 'units_layer_2': 100, 'units_layer_3': 59, 'learning_rate': 0.010076285539499751}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:42:50,414] Trial 17 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 115, 'n_layers': 3, 'units_layer_2': 58, 'units_layer_3': 95, 'units_layer_4': 5, 'learning_rate': 0.0005665992534226866}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:00,326] Trial 18 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 92, 'n_layers': 2, 'units_layer_2': 84, 'units_layer_3': 39, 'learning_rate': 0.002765178931292759}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:10,319] Trial 19 finished with value: 0.9222221970558167 and parameters: {'units_layer_1': 66, 'n_layers': 3, 'units_layer_2': 47, 'units_layer_3': 98, 'units_layer_4': 71, 'learning_rate': 0.00029197078817035424}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:19,314] Trial 20 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 117, 'n_layers': 2, 'units_layer_2': 104, 'units_layer_3': 5, 'learning_rate': 0.021653137915736448}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:28,219] Trial 21 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 100, 'n_layers': 2, 'units_layer_2': 63, 'units_layer_3': 100, 'learning_rate': 0.004684651232312083}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:37,320] Trial 22 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 99, 'n_layers': 2, 'units_layer_2': 48, 'units_layer_3': 78, 'learning_rate': 0.0075124369356288166}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:46,673] Trial 23 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 76, 'n_layers': 2, 'units_layer_2': 77, 'units_layer_3': 108, 'learning_rate': 0.002258650487636049}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:43:55,801] Trial 24 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 109, 'n_layers': 2, 'units_layer_2': 38, 'units_layer_3': 81, 'learning_rate': 0.029500424262417856}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:44:04,979] Trial 25 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 121, 'n_layers': 2, 'units_layer_2': 65, 'units_layer_3': 46, 'learning_rate': 0.0003354254098501523}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:44:14,693] Trial 26 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 94, 'n_layers': 2, 'units_layer_2': 55, 'units_layer_3': 109, 'learning_rate': 0.008074824094960622}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:44:24,126] Trial 27 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 81, 'n_layers': 3, 'units_layer_2': 13, 'units_layer_3': 90, 'units_layer_4': 70, 'learning_rate': 0.0021579445896782773}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:44:33,188] Trial 28 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 55, 'n_layers': 2, 'units_layer_2': 86, 'units_layer_3': 68, 'learning_rate': 0.05058797899376756}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:44:41,749] Trial 29 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 125, 'n_layers': 1, 'units_layer_2': 54, 'learning_rate': 0.012858853862172975}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:44:51,001] Trial 30 finished with value: 0.9185185432434082 and parameters: {'units_layer_1': 104, 'n_layers': 2, 'units_layer_2': 65, 'units_layer_3': 112, 'learning_rate': 0.018675043456773607}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:00,207] Trial 31 finished with value: 0.9185185432434082 and parameters: {'units_layer_1': 86, 'n_layers': 2, 'units_layer_2': 102, 'units_layer_3': 56, 'learning_rate': 0.007639504517237191}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:09,235] Trial 32 finished with value: 0.914814829826355 and parameters: {'units_layer_1': 96, 'n_layers': 2, 'units_layer_2': 126, 'units_layer_3': 17, 'learning_rate': 0.011155329777675884}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:18,668] Trial 33 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 112, 'n_layers': 2, 'units_layer_2': 41, 'units_layer_3': 65, 'learning_rate': 0.0052516962811780645}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:28,033] Trial 34 finished with value: 0.9222221970558167 and parameters: {'units_layer_1': 128, 'n_layers': 2, 'units_layer_2': 107, 'units_layer_3': 86, 'learning_rate': 0.0015296309848784027}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:36,783] Trial 35 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 81, 'n_layers': 1, 'units_layer_2': 90, 'learning_rate': 0.0005562299969588059}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:46,071] Trial 36 finished with value: 0.9185185432434082 and parameters: {'units_layer_1': 69, 'n_layers': 2, 'units_layer_2': 74, 'units_layer_3': 46, 'learning_rate': 0.00014211986653401415}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:45:54,681] Trial 37 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 104, 'n_layers': 1, 'units_layer_2': 114, 'learning_rate': 0.004695831509067511}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:03,968] Trial 38 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 117, 'n_layers': 2, 'units_layer_2': 58, 'units_layer_3': 128, 'learning_rate': 1.8389981657166073e-05}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:13,077] Trial 39 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 57, 'n_layers': 1, 'units_layer_2': 71, 'learning_rate': 4.431453801742789e-05}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:22,830] Trial 40 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 90, 'n_layers': 2, 'units_layer_2': 79, 'units_layer_3': 70, 'learning_rate': 0.0007005959911959037}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:31,880] Trial 41 finished with value: 0.9518518447875977 and parameters: {'units_layer_1': 57, 'n_layers': 1, 'units_layer_2': 23, 'learning_rate': 0.003557407171141907}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:40,219] Trial 42 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 49, 'n_layers': 1, 'units_layer_2': 16, 'learning_rate': 0.0031379880306964306}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:48,595] Trial 43 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 34, 'n_layers': 1, 'units_layer_2': 30, 'learning_rate': 0.0016072048890677676}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:46:56,957] Trial 44 finished with value: 0.9518518447875977 and parameters: {'units_layer_1': 40, 'n_layers': 1, 'units_layer_2': 16, 'learning_rate': 0.01297117739312474}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:05,582] Trial 45 finished with value: 0.9592592716217041 and parameters: {'units_layer_1': 35, 'n_layers': 1, 'units_layer_2': 23, 'learning_rate': 0.0243514814277229}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:14,508] Trial 46 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 37, 'n_layers': 1, 'units_layer_2': 20, 'learning_rate': 0.02798998555812768}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:23,066] Trial 47 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 26, 'n_layers': 1, 'units_layer_2': 6, 'learning_rate': 0.08657839677476051}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:31,796] Trial 48 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 12, 'n_layers': 1, 'units_layer_2': 22, 'learning_rate': 0.01588772969623665}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:40,782] Trial 49 finished with value: 0.9259259104728699 and parameters: {'units_layer_1': 42, 'n_layers': 1, 'units_layer_2': 33, 'learning_rate': 0.039446502595837145}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:49,417] Trial 50 finished with value: 0.9185185432434082 and parameters: {'units_layer_1': 59, 'n_layers': 1, 'units_layer_2': 13, 'learning_rate': 0.017853311252593117}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:47:58,254] Trial 51 finished with value: 0.9407407641410828 and parameters: {'units_layer_1': 31, 'n_layers': 1, 'units_layer_2': 29, 'learning_rate': 0.004995123072036982}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:48:06,642] Trial 52 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 15, 'n_layers': 1, 'units_layer_2': 38, 'learning_rate': 0.06789277855298927}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:48:15,239] Trial 53 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 42, 'n_layers': 1, 'units_layer_2': 49, 'learning_rate': 0.00017447741589820658}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:48:25,251] Trial 54 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 50, 'n_layers': 3, 'units_layer_2': 10, 'units_layer_3': 103, 'units_layer_4': 37, 'learning_rate': 0.007262995642607256}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:48:34,127] Trial 55 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 45, 'n_layers': 1, 'units_layer_2': 4, 'learning_rate': 0.028193736847426924}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:48:42,761] Trial 56 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 71, 'n_layers': 1, 'units_layer_2': 18, 'learning_rate': 0.0034139949123131604}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:48:51,366] Trial 57 finished with value: 0.9407407641410828 and parameters: {'units_layer_1': 122, 'n_layers': 1, 'units_layer_2': 26, 'learning_rate': 0.011751476555603334}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:00,349] Trial 58 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 64, 'n_layers': 2, 'units_layer_2': 44, 'units_layer_3': 26, 'learning_rate': 0.0009389425173638533}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:10,056] Trial 59 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 20, 'n_layers': 3, 'units_layer_2': 69, 'units_layer_3': 114, 'units_layer_4': 98, 'learning_rate': 0.008999362084910058}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:18,500] Trial 60 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 38, 'n_layers': 1, 'units_layer_2': 34, 'learning_rate': 0.00551452469720882}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:27,590] Trial 61 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 83, 'n_layers': 2, 'units_layer_2': 97, 'units_layer_3': 55, 'learning_rate': 0.010731472596205488}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:36,868] Trial 62 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 100, 'n_layers': 2, 'units_layer_2': 61, 'units_layer_3': 13, 'learning_rate': 0.026186020306821697}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:46,166] Trial 63 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 108, 'n_layers': 2, 'units_layer_2': 53, 'units_layer_3': 22, 'learning_rate': 0.0022407065895503927}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:49:56,206] Trial 64 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 75, 'n_layers': 2, 'units_layer_2': 89, 'units_layer_3': 32, 'learning_rate': 0.014111071199820073}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:50:05,516] Trial 65 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 28, 'n_layers': 2, 'units_layer_2': 25, 'units_layer_3': 91, 'learning_rate': 0.006386605748955729}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:50:14,694] Trial 66 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 53, 'n_layers': 2, 'units_layer_2': 10, 'units_layer_3': 74, 'learning_rate': 0.003911247669101343}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:50:23,836] Trial 67 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 62, 'n_layers': 2, 'units_layer_2': 82, 'units_layer_3': 62, 'learning_rate': 0.04602701033160322}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:50:33,365] Trial 68 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 94, 'n_layers': 2, 'units_layer_2': 98, 'units_layer_3': 117, 'learning_rate': 0.022520748739237213}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:50:42,603] Trial 69 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 106, 'n_layers': 2, 'units_layer_2': 68, 'units_layer_3': 46, 'learning_rate': 0.0004591770574451367}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:50:51,923] Trial 70 finished with value: 0.9222221970558167 and parameters: {'units_layer_1': 114, 'n_layers': 2, 'units_layer_2': 60, 'units_layer_3': 38, 'learning_rate': 3.7004087418907854e-05}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:00,456] Trial 71 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 37, 'n_layers': 1, 'units_layer_2': 20, 'learning_rate': 0.033456037400230156}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:08,831] Trial 72 finished with value: 0.8888888955116272 and parameters: {'units_layer_1': 38, 'n_layers': 1, 'units_layer_2': 16, 'learning_rate': 0.02218859879644085}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:17,726] Trial 73 finished with value: 0.9407407641410828 and parameters: {'units_layer_1': 120, 'n_layers': 1, 'units_layer_2': 116, 'learning_rate': 0.014826547107186007}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:26,182] Trial 74 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 45, 'n_layers': 1, 'units_layer_2': 23, 'learning_rate': 0.008990376029176338}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:34,703] Trial 75 finished with value: 0.9555555582046509 and parameters: {'units_layer_1': 34, 'n_layers': 1, 'units_layer_2': 35, 'learning_rate': 0.010633061811815697}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:43,127] Trial 76 finished with value: 0.9074074029922485 and parameters: {'units_layer_1': 23, 'n_layers': 1, 'units_layer_2': 50, 'learning_rate': 0.003943060593495805}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:51:52,972] Trial 77 finished with value: 0.9518518447875977 and parameters: {'units_layer_1': 100, 'n_layers': 3, 'units_layer_2': 35, 'units_layer_3': 82, 'units_layer_4': 14, 'learning_rate': 0.0015278318932739413}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:02,446] Trial 78 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 32, 'n_layers': 3, 'units_layer_2': 37, 'units_layer_3': 104, 'units_layer_4': 6, 'learning_rate': 0.00259120547521004}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:11,895] Trial 79 finished with value: 0.9259259104728699 and parameters: {'units_layer_1': 102, 'n_layers': 3, 'units_layer_2': 44, 'units_layer_3': 94, 'units_layer_4': 38, 'learning_rate': 0.0013399214507352159}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:21,450] Trial 80 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 98, 'n_layers': 3, 'units_layer_2': 30, 'units_layer_3': 82, 'units_layer_4': 26, 'learning_rate': 0.00195655106410877}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:30,399] Trial 81 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 86, 'n_layers': 2, 'units_layer_2': 41, 'units_layer_3': 99, 'learning_rate': 0.006277479288648697}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:39,304] Trial 82 finished with value: 0.9222221970558167 and parameters: {'units_layer_1': 112, 'n_layers': 2, 'units_layer_2': 28, 'units_layer_3': 86, 'learning_rate': 0.00978051888592991}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:48,450] Trial 83 finished with value: 0.9259259104728699 and parameters: {'units_layer_1': 78, 'n_layers': 2, 'units_layer_2': 34, 'units_layer_3': 95, 'learning_rate': 0.00020891996355888644}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:52:57,383] Trial 84 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 97, 'n_layers': 1, 'units_layer_2': 74, 'learning_rate': 1.0429764565829777e-05}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:53:07,201] Trial 85 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 93, 'n_layers': 3, 'units_layer_2': 126, 'units_layer_3': 77, 'units_layer_4': 59, 'learning_rate': 0.003981250553599281}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:53:15,906] Trial 86 finished with value: 0.9555555582046509 and parameters: {'units_layer_1': 109, 'n_layers': 1, 'units_layer_2': 64, 'learning_rate': 0.01921860630600892}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:53:24,474] Trial 87 finished with value: 0.9296296238899231 and parameters: {'units_layer_1': 49, 'n_layers': 1, 'units_layer_2': 66, 'learning_rate': 0.0011156353786554308}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:53:33,059] Trial 88 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 116, 'n_layers': 1, 'units_layer_2': 56, 'learning_rate': 0.0006568263812202329}. Best is trial 13 with value: 0.9592592716217041.\n",
      "[I 2024-09-28 15:53:41,645] Trial 89 finished with value: 0.9629629850387573 and parameters: {'units_layer_1': 109, 'n_layers': 1, 'units_layer_2': 78, 'learning_rate': 0.017151573143437272}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:53:50,329] Trial 90 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 109, 'n_layers': 1, 'units_layer_2': 76, 'learning_rate': 0.056987855196683486}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:53:59,118] Trial 91 finished with value: 0.9111111164093018 and parameters: {'units_layer_1': 124, 'n_layers': 1, 'units_layer_2': 72, 'learning_rate': 0.036296294998953}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:08,142] Trial 92 finished with value: 0.9444444179534912 and parameters: {'units_layer_1': 119, 'n_layers': 1, 'units_layer_2': 79, 'learning_rate': 0.01662378684081792}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:16,642] Trial 93 finished with value: 0.9370370507240295 and parameters: {'units_layer_1': 105, 'n_layers': 1, 'units_layer_2': 62, 'learning_rate': 0.02038300163396624}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:25,312] Trial 94 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 90, 'n_layers': 1, 'units_layer_2': 51, 'learning_rate': 0.011730079730593205}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:33,940] Trial 95 finished with value: 0.9518518447875977 and parameters: {'units_layer_1': 102, 'n_layers': 1, 'units_layer_2': 64, 'learning_rate': 0.008123126610626334}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:42,658] Trial 96 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 112, 'n_layers': 1, 'units_layer_2': 86, 'learning_rate': 0.013356754397377683}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:51,315] Trial 97 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 107, 'n_layers': 1, 'units_layer_2': 64, 'learning_rate': 0.008234632876319647}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:54:59,664] Trial 98 finished with value: 0.9333333373069763 and parameters: {'units_layer_1': 41, 'n_layers': 1, 'units_layer_2': 11, 'learning_rate': 0.007059583431836681}. Best is trial 89 with value: 0.9629629850387573.\n",
      "[I 2024-09-28 15:55:08,603] Trial 99 finished with value: 0.9481481313705444 and parameters: {'units_layer_1': 102, 'n_layers': 1, 'units_layer_2': 67, 'learning_rate': 0.017904971448993716}. Best is trial 89 with value: 0.9629629850387573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.9629629850387573\n",
      "  Params: \n",
      "    units_layer_1: 109\n",
      "    n_layers: 1\n",
      "    units_layer_2: 78\n",
      "    learning_rate: 0.017151573143437272\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Optuna Neural Network\n",
      "Accuracy: 0.9444444179534912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.97      0.99      0.98       246\n",
      "           3       0.53      0.57      0.55        14\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.63      0.58      0.60       270\n",
      "weighted avg       0.93      0.94      0.94       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model(trial):\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(trial.suggest_int('units_layer_1', 4, 128), input_dim=X_train.shape[1], activation='relu'))\n",
    "    \n",
    "    # Add additional layers based on trial suggestions\n",
    "    for i in range(trial.suggest_int('n_layers', 1, 3)):\n",
    "        model.add(Dense(trial.suggest_int(f'units_layer_{i+2}', 4, 128), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(4, activation='softmax'))  # Output layer with 4 neurons for 4 classes\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best trial\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Value: {trial.value}')\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "\n",
    "# Create the best model and add it to the results.csv file\n",
    "model = create_model(trial)\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate the elapsed time in milliseconds\n",
    "elapsed_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Optuna Neural Network\\nAccuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# get macro avg results\n",
    "macro_avg = classification_report(y_test, y_pred_classes, output_dict=True)['macro avg']\n",
    "precision, recall, f1 = macro_avg['precision'], macro_avg['recall'], macro_avg['f1-score']\n",
    "with open(r'C:\\Users\\wesse\\Avans\\Minor\\ML2_Uitstapje\\results.csv', 'a') as f:\n",
    "    f.write(f'\\nNeural Network(Optuna), {precision}, {recall}, {f1}, {elapsed_time_ms}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time(ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.587750</td>\n",
       "      <td>0.614039</td>\n",
       "      <td>0.600134</td>\n",
       "      <td>16.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.812253</td>\n",
       "      <td>0.816420</td>\n",
       "      <td>0.810738</td>\n",
       "      <td>196.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network(1L 8N)</td>\n",
       "      <td>0.792095</td>\n",
       "      <td>0.603150</td>\n",
       "      <td>0.612753</td>\n",
       "      <td>14143.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network(2L 64N-32N)</td>\n",
       "      <td>0.607889</td>\n",
       "      <td>0.608087</td>\n",
       "      <td>0.595572</td>\n",
       "      <td>13833.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network(Optuna)</td>\n",
       "      <td>0.626361</td>\n",
       "      <td>0.578325</td>\n",
       "      <td>0.597690</td>\n",
       "      <td>918363.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Precision    Recall  F1 Score   Time(ms)\n",
       "0         Logistic Regression   0.587750  0.614039  0.600134      16.12\n",
       "1               Random Forest   0.812253  0.816420  0.810738     196.10\n",
       "2       Neural Network(1L 8N)   0.792095  0.603150  0.612753   14143.82\n",
       "3  Neural Network(2L 64N-32N)   0.607889  0.608087  0.595572   13833.34\n",
       "4      Neural Network(Optuna)   0.626361  0.578325  0.597690  918363.45"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data from the results.csv file and plot a benchmark table\n",
    "results = pd.read_csv(r'C:\\Users\\wesse\\Avans\\Minor\\ML2_Uitstapje\\results.csv')\n",
    "results['Time(ms)'] = results['Time(ms)'].apply(lambda x: round(x, 2))\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
